{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECOMMENDER SYSTEMS\n",
    "# it is a system or filtering system that provide suggestions for items that are most pertinent to a particular user\n",
    "\n",
    "import data_lib\n",
    "from data_lib import Vector\n",
    "from typing import List, Tuple, Dict, NamedTuple, List\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import tqdm\n",
    "\n",
    "users_interests = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]\n",
    "\n",
    "popular_interests = Counter(interest\n",
    "                            for user_interests in users_interests\n",
    "                            for interest in user_interests)\n",
    "\n",
    "# suggest the most popular interests that he's not already interested in\n",
    "def most_popular_new_interests(\n",
    "        user_interests: List[str],\n",
    "        max_results: int = 5) -> List[Tuple[str, int]]:\n",
    "    suggestions = [(interest, frequency)\n",
    "                   for interest, frequency in popular_interests.most_common()\n",
    "                   if interest not in user_interests]\n",
    "    return suggestions[:max_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MapReduce', 0.5669467095138409),\n",
       " ('MongoDB', 0.50709255283711),\n",
       " ('Postgres', 0.50709255283711),\n",
       " ('NoSQL', 0.3380617018914066),\n",
       " ('neural networks', 0.1889822365046136),\n",
       " ('deep learning', 0.1889822365046136),\n",
       " ('artificial intelligence', 0.1889822365046136),\n",
       " ('databases', 0.1690308509457033),\n",
       " ('MySQL', 0.1690308509457033),\n",
       " ('Python', 0.1543033499620919),\n",
       " ('R', 0.1543033499620919),\n",
       " ('C++', 0.1543033499620919),\n",
       " ('Haskell', 0.1543033499620919),\n",
       " ('programming languages', 0.1543033499620919)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user-based collaborative filtering\n",
    "# recommed interest based on users similar to the user in focus\n",
    "unique_interests = sorted({interest\n",
    "                           for user_interests in users_interests\n",
    "                           for interest in user_interests})\n",
    "\n",
    "def make_user_interest_vector(user_interests: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Given a list of interests, produce a vector whose ith element is 1\n",
    "    if unique_interests[i] is in the list, 0 otherwise\n",
    "    \"\"\"\n",
    "    return [1 if interest in user_interests else 0\n",
    "            for interest in unique_interests]\n",
    "\n",
    "user_interest_vectors = [make_user_interest_vector(user_interests)\n",
    "                         for user_interests in users_interests]\n",
    "\n",
    "user_similarities = [[data_lib.cosine_similarity(interest_vector_i, interest_vector_j)\n",
    "                      for interest_vector_j in user_interest_vectors]\n",
    "                     for interest_vector_i in user_interest_vectors]\n",
    "\n",
    "# Users 0 and 9 share interests in Hadoop, Java, and Big Data\n",
    "assert 0.56 < user_similarities[0][9] < 0.58, \"several shared interests\"\n",
    "\n",
    "# Users 0 and 8 share only one interest: Big Data\n",
    "assert 0.18 < user_similarities[0][8] < 0.20, \"only one shared interest\"\n",
    "\n",
    "# the function that find the most similar users based on the user similarities\n",
    "def most_similar_users_to(user_id: int) -> List[Tuple[int, float]]:\n",
    "    pairs = [(other_user_id, similarity)                      # Find other\n",
    "             for other_user_id, similarity in                 # users with\n",
    "                enumerate(user_similarities[user_id])         # nonzero\n",
    "             if user_id != other_user_id and similarity > 0]  # similarity.\n",
    "\n",
    "    return sorted(pairs,                                      # Sort them\n",
    "                  key=lambda pair: pair[-1],                  # most similar\n",
    "                  reverse=True)                               # first.\n",
    "\n",
    "def user_based_suggestions(user_id: int,\n",
    "                           include_current_interests: bool = False):\n",
    "    # Sum up the similarities\n",
    "    suggestions: Dict[str, float] = defaultdict(float)\n",
    "    for other_user_id, similarity in most_similar_users_to(user_id):\n",
    "        for interest in users_interests[other_user_id]:\n",
    "            suggestions[interest] += similarity\n",
    "\n",
    "    # Convert them to a sorted list\n",
    "    suggestions = sorted(suggestions.items(),\n",
    "                         key=lambda pair: pair[-1],  # weight\n",
    "                         reverse=True)\n",
    "\n",
    "    # And (maybe) exclude already interests\n",
    "    if include_current_interests:\n",
    "        return suggestions\n",
    "    else:\n",
    "        return [(suggestion, weight)\n",
    "                for suggestion, weight in suggestions\n",
    "                if suggestion not in users_interests[user_id]]\n",
    "\n",
    "user_based_suggestions(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MySQL', 1.9915638315627207),\n",
       " ('databases', 1.9915638315627207),\n",
       " ('Spark', 1.2844570503761732),\n",
       " ('Storm', 1.2844570503761732),\n",
       " ('Hadoop', 0.9082482904638631),\n",
       " ('Big Data', 0.7415816237971964),\n",
       " ('Java', 0.7415816237971964)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item based collaborative filtering\n",
    "# find similarities between interests and then suggest them to the users based on their current interests\n",
    "interest_user_matrix = [[user_interest_vector[j]\n",
    "                         for user_interest_vector in user_interest_vectors]\n",
    "                        for j, _ in enumerate(unique_interests)]\n",
    "\n",
    "interest_similarities = [[data_lib.cosine_similarity(user_vector_i, user_vector_j)\n",
    "                          for user_vector_j in interest_user_matrix]\n",
    "                         for user_vector_i in interest_user_matrix]\n",
    "\n",
    "def most_similar_interests_to(interest_id: int):\n",
    "    similarities = interest_similarities[interest_id]\n",
    "    pairs = [(unique_interests[other_interest_id], similarity)\n",
    "             for other_interest_id, similarity in enumerate(similarities)\n",
    "             if interest_id != other_interest_id and similarity > 0]\n",
    "    return sorted(pairs,\n",
    "                  key=lambda pair: pair[-1],\n",
    "                  reverse=True)\n",
    "\n",
    "def item_based_suggestions(user_id: int,\n",
    "                           include_current_interests: bool = False):\n",
    "    # Add up the similar interests\n",
    "    suggestions = defaultdict(float)\n",
    "    user_interest_vector = user_interest_vectors[user_id]\n",
    "    for interest_id, is_interested in enumerate(user_interest_vector):\n",
    "        if is_interested == 1:\n",
    "            similar_interests = most_similar_interests_to(interest_id)\n",
    "            for interest, similarity in similar_interests:\n",
    "                suggestions[interest] += similarity\n",
    "    # Sort them by weight\n",
    "    suggestions = sorted(suggestions.items(),\n",
    "                         key=lambda pair: pair[-1],\n",
    "                         reverse=True)\n",
    "    if include_current_interests:\n",
    "        return suggestions\n",
    "    else:\n",
    "        return [(suggestion, weight)\n",
    "                for suggestion, weight in suggestions\n",
    "                if suggestion not in users_interests[user_id]]\n",
    "\n",
    "item_based_suggestions(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36 Star Wars (1977)\n",
      "4.20 Empire Strikes Back, The (1980)\n",
      "4.01 Return of the Jedi (1983)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 15.800353931113415:   0%|          | 81/70000 [00:00<01:26, 804.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.045000000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 5.906486311829125: 100%|██████████| 70000/70000 [02:09<00:00, 540.30it/s] \n",
      "avg loss: 1.3334406499406923: 100%|██████████| 15000/15000 [00:23<00:00, 632.96it/s]\n",
      "avg loss: 1.1943113618908168:   0%|          | 71/70000 [00:00<02:07, 548.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.04050000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 1.1247010778645978: 100%|██████████| 70000/70000 [01:55<00:00, 608.67it/s]\n",
      "avg loss: 1.1286335644930559: 100%|██████████| 15000/15000 [00:22<00:00, 658.72it/s]\n",
      "avg loss: 1.0724327011826416:   0%|          | 59/70000 [00:00<02:01, 574.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.03645000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 1.0224488991967522: 100%|██████████| 70000/70000 [01:52<00:00, 622.77it/s]\n",
      "avg loss: 1.0768163501335413: 100%|██████████| 15000/15000 [00:23<00:00, 647.25it/s]\n",
      "avg loss: 0.9329719264809511:   0%|          | 77/70000 [00:00<01:53, 616.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.03280500000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.982001417450082: 100%|██████████| 70000/70000 [01:46<00:00, 655.08it/s] \n",
      "avg loss: 1.04870564284301: 100%|██████████| 15000/15000 [00:22<00:00, 653.22it/s]  \n",
      "avg loss: 0.9960394259941151:   0%|          | 74/70000 [00:00<01:34, 739.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.02952450000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.9550964662941216: 100%|██████████| 70000/70000 [02:00<00:00, 580.08it/s]\n",
      "avg loss: 1.029697080158141: 100%|██████████| 15000/15000 [00:24<00:00, 606.67it/s] \n",
      "avg loss: 0.8903786144238042:   0%|          | 63/70000 [00:00<01:51, 629.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.02657205000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.9338692188514185: 100%|██████████| 70000/70000 [01:24<00:00, 828.34it/s] \n",
      "avg loss: 1.0152951983045033: 100%|██████████| 15000/15000 [00:15<00:00, 974.02it/s] \n",
      "avg loss: 0.8753645235873891:   0%|          | 113/70000 [00:00<01:10, 991.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.02391484500000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.9158617002186215: 100%|██████████| 70000/70000 [01:17<00:00, 908.14it/s] \n",
      "avg loss: 1.00359116222027: 100%|██████████| 15000/15000 [00:15<00:00, 953.89it/s]   \n",
      "avg loss: 0.896580967565084:   0%|          | 93/70000 [00:00<01:15, 920.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.021523360500000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.9000973588150043: 100%|██████████| 70000/70000 [01:15<00:00, 928.00it/s] \n",
      "avg loss: 0.9936613594954907: 100%|██████████| 15000/15000 [00:18<00:00, 821.64it/s]\n",
      "avg loss: 0.9057495545692322:   0%|          | 88/70000 [00:00<01:20, 871.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.01937102445000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8861268156673043: 100%|██████████| 70000/70000 [01:32<00:00, 757.71it/s] \n",
      "avg loss: 0.9850315897870007: 100%|██████████| 15000/15000 [00:16<00:00, 931.85it/s] \n",
      "avg loss: 0.8704832418109834:   0%|          | 79/70000 [00:00<01:28, 790.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.01743392200500001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8736996045416049: 100%|██████████| 70000/70000 [01:17<00:00, 908.61it/s] \n",
      "avg loss: 0.9774453296910613: 100%|██████████| 15000/15000 [00:15<00:00, 943.46it/s] \n",
      "avg loss: 0.8922983782456926:   0%|          | 88/70000 [00:00<01:20, 871.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.015690529804500006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8626373014686425: 100%|██████████| 70000/70000 [01:15<00:00, 930.91it/s] \n",
      "avg loss: 0.9707497290082151: 100%|██████████| 15000/15000 [00:16<00:00, 924.44it/s]\n",
      "avg loss: 0.8308707221576893:   0%|          | 115/70000 [00:00<01:01, 1138.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.014121476824050006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8527881050006498: 100%|██████████| 70000/70000 [01:15<00:00, 927.91it/s] \n",
      "avg loss: 0.9648385879249967: 100%|██████████| 15000/15000 [00:16<00:00, 913.46it/s] \n",
      "avg loss: 0.8389898078463022:   0%|          | 103/70000 [00:00<01:08, 1019.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.012709329141645007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8440140067839375: 100%|██████████| 70000/70000 [01:14<00:00, 933.82it/s] \n",
      "avg loss: 0.9596257175128688: 100%|██████████| 15000/15000 [00:15<00:00, 937.68it/s] \n",
      "avg loss: 0.8661493851571879:   0%|          | 98/70000 [00:00<01:14, 942.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.011438396227480507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8361888523033255: 100%|██████████| 70000/70000 [01:00<00:00, 1159.98it/s]\n",
      "avg loss: 0.955034156559941: 100%|██████████| 15000/15000 [00:10<00:00, 1424.77it/s] \n",
      "avg loss: 0.8234050874119632:   0%|          | 141/70000 [00:00<00:50, 1382.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.010294556604732457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8291988257567187: 100%|██████████| 70000/70000 [00:54<00:00, 1295.82it/s]\n",
      "avg loss: 0.9509928878646497: 100%|██████████| 15000/15000 [00:12<00:00, 1204.82it/s]\n",
      "avg loss: 0.8577684151974989:   0%|          | 102/70000 [00:00<01:08, 1019.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.00926510094425921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.82294275638821: 100%|██████████| 70000/70000 [00:49<00:00, 1404.07it/s]  \n",
      "avg loss: 0.9474365569223078: 100%|██████████| 15000/15000 [00:10<00:00, 1436.78it/s]\n",
      "avg loss: 0.786619608552237:   0%|          | 143/70000 [00:00<00:49, 1415.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.00833859084983329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8173317855788919: 100%|██████████| 70000/70000 [00:49<00:00, 1411.23it/s]\n",
      "avg loss: 0.9443060204154082: 100%|██████████| 15000/15000 [00:10<00:00, 1387.35it/s]\n",
      "avg loss: 0.8089441180317216:   0%|          | 99/70000 [00:00<01:15, 925.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.007504731764849962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8122885410797746: 100%|██████████| 70000/70000 [00:49<00:00, 1402.98it/s]\n",
      "avg loss: 0.9415487965523057: 100%|██████████| 15000/15000 [00:10<00:00, 1386.42it/s]\n",
      "avg loss: 0.7767205812796536:   0%|          | 160/70000 [00:00<00:43, 1599.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.006754258588364966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8077460482304591: 100%|██████████| 70000/70000 [00:48<00:00, 1451.07it/s]\n",
      "avg loss: 0.9391190980530327: 100%|██████████| 15000/15000 [00:10<00:00, 1405.38it/s]\n",
      "avg loss: 0.7807717372024867:   0%|          | 140/70000 [00:00<00:49, 1399.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.00607883272952847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8036465508301924: 100%|██████████| 70000/70000 [00:51<00:00, 1362.84it/s]\n",
      "avg loss: 0.9369774221882966: 100%|██████████| 15000/15000 [00:10<00:00, 1376.24it/s]\n",
      "avg loss: 0.9228861830083157: 100%|██████████| 15000/15000 [00:10<00:00, 1401.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# This points to the current directory, modify if your files are elsewhere.\n",
    "MOVIES = \"u.item\"   # pipe-delimited: movie_id|title|...\n",
    "RATINGS = \"u.data\"  # tab-delimited: user_id, movie_id, rating, timestamp\n",
    "\n",
    "class Rating(NamedTuple):\n",
    "    user_id: str\n",
    "    movie_id: str\n",
    "    rating: float\n",
    "\n",
    "import csv\n",
    "# We specify this encoding to avoid a UnicodeDecodeError.\n",
    "# See: https://stackoverflow.com/a/53136168/1076346.\n",
    "with open(MOVIES, encoding=\"iso-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"|\")\n",
    "    movies = {movie_id: title for movie_id, title, *_ in reader}\n",
    "\n",
    "# Create a list of [Rating]\n",
    "with open(RATINGS, encoding=\"iso-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    ratings = [Rating(user_id, movie_id, float(rating))\n",
    "               for user_id, movie_id, rating, _ in reader]\n",
    "\n",
    "# 1682 movies rated by 943 users\n",
    "assert len(movies) == 1682\n",
    "assert len(list({rating.user_id for rating in ratings})) == 943\n",
    "\n",
    "# Data structure for accumulating ratings by movie_id\n",
    "star_wars_ratings = {movie_id: []\n",
    "                     for movie_id, title in movies.items()\n",
    "                     if re.search(\"Star Wars|Empire Strikes|Jedi\", title)}\n",
    "\n",
    "# Iterate over ratings, accumulating the Star Wars ones\n",
    "for rating in ratings:\n",
    "    if rating.movie_id in star_wars_ratings:\n",
    "        star_wars_ratings[rating.movie_id].append(rating.rating)\n",
    "\n",
    "# Compute the average rating for each movie\n",
    "avg_ratings = [(sum(title_ratings) / len(title_ratings), movie_id)\n",
    "               for movie_id, title_ratings in star_wars_ratings.items()]\n",
    "\n",
    "# And then print them in order\n",
    "for avg_rating, movie_id in sorted(avg_ratings, reverse=True):\n",
    "    print(f\"{avg_rating:.2f} {movies[movie_id]}\")\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(ratings)\n",
    "split1 = int(len(ratings) * 0.7)\n",
    "split2 = int(len(ratings) * 0.85)\n",
    "\n",
    "train = ratings[:split1]              # 70% of the data\n",
    "validation = ratings[split1:split2]   # 15% of the data\n",
    "test = ratings[split2:]               # 15% of the data\n",
    "EMBEDDING_DIM = 2\n",
    "\n",
    "# Find unique ids\n",
    "user_ids = {rating.user_id for rating in ratings}\n",
    "movie_ids = {rating.movie_id for rating in ratings}\n",
    "\n",
    "# Then create a random vector per id\n",
    "user_vectors = {user_id: data_lib.random_tensor(EMBEDDING_DIM)\n",
    "                for user_id in user_ids}\n",
    "movie_vectors = {movie_id: data_lib.random_tensor(EMBEDDING_DIM)\n",
    "                 for movie_id in movie_ids}\n",
    "\n",
    "def loop(dataset: List[Rating],\n",
    "         learning_rate: float = None) -> None:\n",
    "    with tqdm.tqdm(dataset) as t:\n",
    "        loss = 0.0\n",
    "        for i, rating in enumerate(t):\n",
    "            movie_vector = movie_vectors[rating.movie_id]\n",
    "            user_vector = user_vectors[rating.user_id]\n",
    "            predicted = data_lib.dot(user_vector, movie_vector)\n",
    "            error = predicted - rating.rating\n",
    "            loss += error ** 2\n",
    "            if learning_rate is not None:\n",
    "                #     predicted = m_0 * u_0 + ... + m_k * u_k\n",
    "                # So each u_j enters output with coefficent m_j\n",
    "                # and each m_j enters output with coefficient u_j\n",
    "                user_gradient = [error * m_j for m_j in movie_vector]\n",
    "                movie_gradient = [error * u_j for u_j in user_vector]\n",
    "                # Take gradient steps\n",
    "                for j in range(EMBEDDING_DIM):\n",
    "                    user_vector[j] -= learning_rate * user_gradient[j]\n",
    "                    movie_vector[j] -= learning_rate * movie_gradient[j]\n",
    "            t.set_description(f\"avg loss: {loss / (i + 1)}\")\n",
    "\n",
    "learning_rate = 0.05\n",
    "for epoch in range(20):\n",
    "    learning_rate *= 0.9\n",
    "    print(epoch, learning_rate)\n",
    "    loop(train, learning_rate=learning_rate)\n",
    "    loop(validation)\n",
    "loop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dv: 4498.670: 100%|██████████| 100/100 [00:00<00:00, 150.82it/s]\n",
      "dv: 918.680: 100%|██████████| 100/100 [00:00<00:00, 164.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('867', 4.0, 'Whole Wide World, The (1996)', [-2.5970167533205437, 0.49616545456288086]), ('1643', 3.75, 'Angel Baby (1995)', [-2.500018328131252, -1.0502775007078067]), ('1656', 3.5, 'Little City (1998)', [-2.4973162580535466, 1.0618592887204512]), ('1344', 3.2, 'Story of Xinghua, The (1993)', [-2.4750948408247697, 0.0014176574405233566]), ('851', 3.75, 'Two or Three Things I Know About Her (1966)', [-2.424064072967121, 0.5257567166972834]), ('1636', 4.0, 'Brothers in Trouble (1995)', [-2.4062766742292525, 0.25061494925898287]), ('1642', 4.5, \"Some Mother's Son (1996)\", [-2.405134328701133, 0.6728197708023246]), ('814', 5.0, 'Great Day in Harlem, A (1994)', [-2.367438598355158, 0.8748317537993482]), ('1367', 4.2, 'Faust (1994)', [-2.3611984575107785, -0.593444568735537]), ('114', 4.447761194029851, 'Wallace & Gromit: The Best of Aardman Animation (1996)', [-2.3494284691322127, 0.39988324571430933]), ('868', 3.8, 'Hearts and Minds (1996)', [-2.340005890414335, 0.5274967779702815]), ('1660', 2.0, 'Small Faces (1995)', [-2.335198663342994, -0.7647417077957851]), ('169', 4.466101694915254, 'Wrong Trousers, The (1993)', [-2.329225464073253, -0.39442941063831705]), ('64', 4.445229681978798, 'Shawshank Redemption, The (1994)', [-2.325004894059429, 0.19028095415027524]), ('1062', 3.75, 'Four Days in September (1997)', [-2.317632595934081, -0.32326433185558034]), ('119', 4.5, 'Maya Lin: A Strong Clear Vision (1994)', [-2.3156527076866213, -0.216763531605223]), ('1467', 5.0, 'Saint of Fort Washington, The (1993)', [-2.3063467955492474, -0.8437535618187785]), ('408', 4.491071428571429, 'Close Shave, A (1995)', [-2.3049058345163704, -0.10964495213828407]), ('483', 4.45679012345679, 'Casablanca (1942)', [-2.29877398989027, -0.43191106842781957]), ('811', 3.9444444444444446, 'Thirty-Two Short Films About Glenn Gould (1993)', [-2.2921656448561167, 0.11285662921125494]), ('1650', 4.0, 'Butcher Boy, The (1998)', [-2.283650802485117, 1.4942985460889462]), ('285', 4.265432098765432, 'Secrets & Lies (1996)', [-2.28317541742961, -0.10324820601952056]), ('1558', 3.5714285714285716, 'Aparajito (1956)', [-2.2801687929803416, -1.0944901054758274]), ('1482', 4.0, 'Gate of Heavenly Peace, The (1995)', [-2.276340074370535, 0.07260802358570051]), ('318', 4.466442953020135, \"Schindler's List (1993)\", [-2.268914119971111, 0.17236530136617512])]\n",
      "[('1581', 1.0, 'Woman in Question, The (1950)', [0.5179824609938026, -1.3818420057723428]), ('1373', 1.0, 'Good Morning (1971)', [0.5873143668953948, -0.0374433200944046]), ('1637', 3.0, 'Girls Town (1996)', [0.7138737833818707, -0.4792764297839269]), ('1359', 1.0, 'Boys in Venice (1996)', [0.7164669712869496, -0.1942091144194506]), ('1498', 4.0, 'Farmer & Chase (1995)', [0.7286253828299767, 0.15771349981296146]), ('1661', 1.0, 'New Age, The (1994)', [0.7592906261964576, 0.7276807712058619]), ('1595', 2.0, 'Shopping (1994)', [0.7857133250882791, -0.8803693043906828]), ('1494', 1.0, 'Mostro, Il (1994)', [0.8300686432962657, 0.5947683520529011]), ('852', 1.0, 'Bloody Child, The (1996)', [0.8818922336210315, 1.3214098625952413]), ('1633', 3.0, 'Á köldum klaka (Cold Fever) (1994)', [0.8862280598982212, 0.46017922916960724]), ('1562', 1.0, \"Eye of Vichy, The (Oeil de Vichy, L') (1993)\", [0.8865780815409696, -1.2661849012904516]), ('1130', 4.0, \"Jupiter's Wife (1994)\", [1.0014696847020472, 1.1939813911190544]), ('1349', 1.0, 'Mille bolle blu (1993)', [1.001682154743134, 0.18921300371694094]), ('1606', 2.0, 'Deceiver (1997)', [1.0237783192741656, 1.1025881828194504]), ('1576', 1.0, 'Hungarian Fairy Tale, A (1987)', [1.0942080654353814, -0.9620213586356123]), ('1678', 1.0, \"Mat' i syn (1997)\", [1.109492907212415, 0.19059217599238676]), ('1667', 3.0, 'Next Step, The (1995)', [1.144670196757511, -1.0374250074407592]), ('1588', 2.0, 'Salut cousin! (1996)', [1.272245672731125, 1.5499006352801727]), ('1546', 1.0, 'Shadows (Cienie) (1988)', [1.4435336833285544, -0.8404695122989583]), ('1613', 4.0, 'Tokyo Fist (1995)', [1.5131452750300516, -1.1609562801321218]), ('1641', 3.0, 'Dadetown (1995)', [1.518640073443414, 0.7079227801880386]), ('1343', 1.0, 'Lotto Land (1995)', [1.6460001255418928, -0.8245615820860879]), ('1648', 2.0, 'Niagara, Niagara (1997)', [1.865847578786288, 1.5965784086213204]), ('1596', 2.0, 'Nemesis 2: Nebula (1995)', [2.1228090104094792, 1.0987795489511223]), ('1567', 1.0, 'Careful (1992)', [2.6126971049233503, -1.289816035499196])]\n"
     ]
    }
   ],
   "source": [
    "original_vectors = [vector for vector in movie_vectors.values()]\n",
    "components = data_lib.pca(original_vectors, 2)\n",
    "\n",
    "ratings_by_movie = defaultdict(list)\n",
    "for rating in ratings:\n",
    "    ratings_by_movie[rating.movie_id].append(rating.rating)\n",
    "\n",
    "vectors = [\n",
    "    (movie_id,\n",
    "     sum(ratings_by_movie[movie_id]) / len(ratings_by_movie[movie_id]),\n",
    "     movies[movie_id],\n",
    "     vector)\n",
    "    for movie_id, vector in zip(movie_vectors.keys(), data_lib.transform(original_vectors, components))\n",
    "]\n",
    "\n",
    "# Print top 25 and bottom 25 by first principal component\n",
    "print(sorted(vectors, key=lambda v: v[-1][0])[:25])\n",
    "print(sorted(vectors, key=lambda v: v[-1][0])[-25:])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99a4e34db7e30f36b1ef5457f416347a7ea235dd25b8ab561424bdae8460da4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
